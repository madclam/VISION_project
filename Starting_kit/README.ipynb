{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> \n",
    "KEEP THE HEADER BUT EDIT IT; KEEP THE DISCLAIMER\n",
    "\n",
    "<br><img src=\"iris.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>Iris Challenge Starting Kit</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 2.7.13 | Anaconda 4.3.1 (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "<p><br>\n",
    "\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<div style=\"background:#FFFFAA\"> \n",
    "EDIT<br>\n",
    "Iris is a small standard multi-class classification data set from the <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">UCI Machine Learning Repository</a>, formatted in the AutoML format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'          \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Exploratory data analysis\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: dir: command not found\r\n"
     ]
    }
   ],
   "source": [
    "datadir = 'sample_data'              # Change this to the directory where you put the input data\n",
    "dataname = 'cifar10'\n",
    "!dir $datadir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample_data/cifar10_train from AutoML format\n",
      "Number of examples = 1000\n",
      "Number of features = 256\n",
      "Number of classes = 10\n"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data = read_as_df(datadir  + '/' + dataname)                # The data are loaded as a Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.237825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.582240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.13465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.72576</td>\n",
       "      <td>2.518420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.867780</td>\n",
       "      <td>2.79299</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.64746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.213560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.73826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755148</td>\n",
       "      <td>1.46196</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.704580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.831314</td>\n",
       "      <td>3.63862</td>\n",
       "      <td>0.924173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.002000</td>\n",
       "      <td>2.84157</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114685</td>\n",
       "      <td>1.914960</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118838</td>\n",
       "      <td>1.791660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.36946</td>\n",
       "      <td>0.722686</td>\n",
       "      <td>3.82811</td>\n",
       "      <td>0.411937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.211020</td>\n",
       "      <td>3.02779</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.929534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436912</td>\n",
       "      <td>...</td>\n",
       "      <td>1.515330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.957710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.208070</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.000000        0.0   0.000000   0.971831    0.00000   0.237825   \n",
       "1   0.705386        0.0   0.953680   0.000000    3.64746   0.000000   \n",
       "2   0.000000        0.0   0.000000   0.000000    0.00000   0.000000   \n",
       "3   0.000000        0.0   0.114685   1.914960    0.00000   0.000000   \n",
       "4   0.000000        0.0   0.000000   0.000000    0.00000   0.929534   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10     ...      feature_248  \\\n",
       "0        0.0   0.000000   4.582240    0.000000     ...         1.071270   \n",
       "1        0.0   0.000000   0.206124    0.000000     ...         1.213560   \n",
       "2        0.0   0.000000   3.704580    0.000000     ...         0.517879   \n",
       "3        0.0   0.118838   1.791660    0.000000     ...         0.347925   \n",
       "4        0.0   0.000000   0.000000    0.436912     ...         1.515330   \n",
       "\n",
       "   feature_249  feature_250  feature_251  feature_252  feature_253  \\\n",
       "0          0.0      1.13465     0.000000      3.72576     2.518420   \n",
       "1          0.0      0.00000     0.000000      1.73826     0.000000   \n",
       "2          0.0      0.00000     0.831314      3.63862     0.924173   \n",
       "3          0.0      2.36946     0.722686      3.82811     0.411937   \n",
       "4          0.0      0.00000     0.000000      0.00000     2.957710   \n",
       "\n",
       "   feature_254  feature_255  feature_256      target  \n",
       "0          0.0     1.867780      2.79299        frog  \n",
       "1          0.0     0.755148      1.46196  automobile  \n",
       "2          0.0     4.002000      2.84157        frog  \n",
       "3          0.0     2.211020      3.02779        frog  \n",
       "4          0.0     1.208070      0.00000        ship  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>feature_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.292992</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.700226</td>\n",
       "      <td>0.400874</td>\n",
       "      <td>1.294882</td>\n",
       "      <td>0.277236</td>\n",
       "      <td>0.531522</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.507029</td>\n",
       "      <td>0.670609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433320</td>\n",
       "      <td>0.354934</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>0.511755</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.679792</td>\n",
       "      <td>2.205072</td>\n",
       "      <td>0.641289</td>\n",
       "      <td>1.666970</td>\n",
       "      <td>0.693792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.596710</td>\n",
       "      <td>0.163784</td>\n",
       "      <td>1.435478</td>\n",
       "      <td>1.327785</td>\n",
       "      <td>1.516483</td>\n",
       "      <td>0.602914</td>\n",
       "      <td>1.094835</td>\n",
       "      <td>0.274350</td>\n",
       "      <td>0.931115</td>\n",
       "      <td>1.445104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.609955</td>\n",
       "      <td>0.163639</td>\n",
       "      <td>0.832284</td>\n",
       "      <td>0.754649</td>\n",
       "      <td>1.370731</td>\n",
       "      <td>1.837833</td>\n",
       "      <td>1.765438</td>\n",
       "      <td>1.688540</td>\n",
       "      <td>1.226615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.012585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.201800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.304501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.135430</td>\n",
       "      <td>0.173835</td>\n",
       "      <td>0.539599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666647</td>\n",
       "      <td>0.440641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>0.531211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.464264</td>\n",
       "      <td>0.727678</td>\n",
       "      <td>3.426335</td>\n",
       "      <td>0.075498</td>\n",
       "      <td>2.671687</td>\n",
       "      <td>0.916790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.420420</td>\n",
       "      <td>1.708790</td>\n",
       "      <td>7.588520</td>\n",
       "      <td>10.957100</td>\n",
       "      <td>7.243310</td>\n",
       "      <td>3.931260</td>\n",
       "      <td>7.051080</td>\n",
       "      <td>3.224520</td>\n",
       "      <td>5.644760</td>\n",
       "      <td>9.508800</td>\n",
       "      <td>...</td>\n",
       "      <td>6.260280</td>\n",
       "      <td>3.455330</td>\n",
       "      <td>2.338530</td>\n",
       "      <td>5.383730</td>\n",
       "      <td>4.494660</td>\n",
       "      <td>6.880400</td>\n",
       "      <td>8.262500</td>\n",
       "      <td>11.453600</td>\n",
       "      <td>6.874390</td>\n",
       "      <td>6.151250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_1    feature_2    feature_3    feature_4    feature_5  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.292992     0.035396     0.700226     0.400874     1.294882   \n",
       "std       0.596710     0.163784     1.435478     1.327785     1.516483   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.739275   \n",
       "75%       0.304501     0.000000     0.435712     0.000000     2.135430   \n",
       "max       4.420420     1.708790     7.588520    10.957100     7.243310   \n",
       "\n",
       "         feature_6    feature_7    feature_8    feature_9   feature_10  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.277236     0.531522     0.065868     0.507029     0.670609   \n",
       "std       0.602914     1.094835     0.274350     0.931115     1.445104   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.173835     0.539599     0.000000     0.666647     0.440641   \n",
       "max       3.931260     7.051080     3.224520     5.644760     9.508800   \n",
       "\n",
       "          ...       feature_247  feature_248  feature_249  feature_250  \\\n",
       "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      ...          0.433320     0.354934     0.023223     0.511755   \n",
       "std       ...          0.997405     0.609955     0.163639     0.832284   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.054449     0.531211     0.000000     0.819891   \n",
       "max       ...          6.260280     3.455330     2.338530     5.383730   \n",
       "\n",
       "       feature_251  feature_252  feature_253  feature_254  feature_255  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.389800     0.679792     2.205072     0.641289     1.666970   \n",
       "std       0.754649     1.370731     1.837833     1.765438     1.688540   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.606006     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     2.012585     0.000000     1.201800   \n",
       "75%       0.464264     0.727678     3.426335     0.075498     2.671687   \n",
       "max       4.494660     6.880400     8.262500    11.453600     6.874390   \n",
       "\n",
       "       feature_256  \n",
       "count  1000.000000  \n",
       "mean      0.693792  \n",
       "std       1.226615  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.916790  \n",
       "max       6.151250  \n",
       "\n",
       "[8 rows x 256 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\"> Provide your own graphics </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.hist(figsize=(100, 100), bins=50, layout=(1, 256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(data, hue=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data with DataManager\n",
    "We reload the data with the AutoML DataManager class because this is more convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_public.info\n",
      "DataManager : cifar10\n",
      "info:\n",
      "\ttask = multiclass.classification\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tname = cifar10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tfeat_type = Numerical\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tis_sparse = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tmetric = accuracy_metric\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\ttarget_type = Numerical\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\ttest_num = 10000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tlabel_num = 10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\ttarget_num = 1\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tvalid_num = 10000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\thas_categorical = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tusage = dataset cifar10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\tfeat_num = 256\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\ttime_budget = 1200\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\ttrain_num = 40000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\thas_missing = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(0,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(dataname, datadir, replace_missing=True)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a predictive model\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import model\n",
    "??model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the model (run the constructor) and attempt to reload a previously saved version from `sample_code_submission/`:\n",
    "<div style=\"background:#FFFFAA\"> \n",
    "Keep the original data format for inputs/outputs. I put the conversion to categorical target values IN model.py.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = model()\n",
    "trained_model_name = model_dir + dataname\n",
    "#M = M.load(trained_model_name) # Attempts to re-load an already trained model\n",
    "#M.define_model('GaussianNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isabelle: remove this.\n",
    "\n",
    "import numpy as np\n",
    "def convert_label(y):\n",
    "    y_convert = np.zeros((len(y),))\n",
    "    for cpt, i in enumerate(y):\n",
    "        #print(np.where(i == 1)[0][0])\n",
    "        y_convert[cpt] = np.where(i == 1)[0][0]\n",
    "        \n",
    "    return y_convert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and run your predictive model. If you saved have an aldeady trained model saved in sample_code_submission, the evaluation script will reload it and not retrain, just test. This will happen the second time you run the code because when the model is trained it gets saved. So delete iris_model.pickle from sample_code_submission if you do not want this to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Converting to numeric vector\n",
      "[ 6.  1.  6.  6.  8.  8.  3.  4.  6.  0.  6.  9.  0.  3.  6.  6.  5.  4.\n",
      "  8.  3.  2.  6.  4.  0.  3.  1.  4.  0.  6.  6.  2.  7.  6.  3.  9.  0.\n",
      "  4.  5.  7.  1.  6.  7.  9.  1.  2.  7.  7.  8.  0.  3.  7.  4.  7.  3.\n",
      "  1.  4.  0.  4.  6.  6.  1.  4.  9.  2.  6.  4.  4.  5.  0.  4.  6.  0.\n",
      "  8.  3.  4.  8.  8.  1.  3.  9.  5.  7.  1.  9.  4.  7.  9.  1.  4.  9.\n",
      "  7.  5.  2.  7.  3.  4.  8.  8.  2.  2.  1.  5.  9.  2.  7.  8.  8.  6.\n",
      "  8.  8.  2.  8.  1.  3.  8.  8.  5.  4.  7.  1.  6.  6.  3.  1.  6.  1.\n",
      "  6.  7.  0.  4.  6.  9.  5.  8.  8.  7.  1.  9.  0.  3.  3.  7.  6.  9.\n",
      "  0.  0.  4.  7.  1.  4.  3.  4.  3.  9.  8.  6.  7.  0.  8.  3.  9.  1.\n",
      "  0.  8.  0.  9.  8.  4.  0.  2.  1.  4.  2.  7.  1.  7.  0.  5.  2.  9.\n",
      "  7.  9.  8.  6.  4.  4.  1.  1.  6.  7.  8.  8.  6.  4.  5.  6.  3.  9.\n",
      "  4.  6.  2.  5.  3.  6.  7.  7.  3.  9.  1.  3.  4.  1.  8.  3.  3.  5.\n",
      "  6.  4.  0.  9.  6.  7.  3.  6.  5.  0.  6.  2.  0.  5.  4.  9.  3.  1.\n",
      "  4.  6.  0.  6.  7.  0.  7.  2.  6.  9.  1.  6.  5.  4.  5.  4.  7.  7.\n",
      "  6.  8.  1.  4.  5.  9.  7.  8.  8.  7.  1.  4.  6.  4.  6.  2.  2.  5.\n",
      "  0.  3.  8.  9.  4.  1.  1.  2.  4.  1.  9.  6.  3.  3.  6.  9.  5.  7.\n",
      "  3.  6.  9.  4.  2.  4.  0.  0.  0.  8.  7.  9.  5.  1.  8.  6.  7.  0.\n",
      "  1.  7.  7.  8.  6.  2.  7.  4.  8.  8.  9.  8.  9.  8.  2.  9.  8.  9.\n",
      "  1.  3.  5.  7.  4.  0.  1.  4.  1.  9.  4.  0.  8.  4.  3.  7.  9.  7.\n",
      "  7.  9.  3.  3.  6.  9.  8.  1.  5.  9.  8.  5.  5.  6.  3.  3.  3.  0.\n",
      "  5.  1.  0.  6.  7.  3.  8.  0.  9.  0.  7.  0.  4.  8.  8.  0.  7.  5.\n",
      "  0.  3.  9.  0.  8.  6.  8.  7.  7.  6.  9.  4.  9.  1.  0.  8.  0.  6.\n",
      "  6.  7.  1.  6.  2.  8.  1.  1.  6.  0.  5.  4.  7.  8.  8.  1.  7.  4.\n",
      "  9.  6.  9.  8.  1.  2.  6.  1.  1.  8.  5.  3.  7.  4.  7.  1.  9.  2.\n",
      "  6.  9.  2.  4.  1.  0.  8.  2.  5.  2.  0.  0.  6.  6.  0.  8.  1.  4.\n",
      "  9.  2.  5.  8.  2.  2.  5.  8.  2.  5.  3.  4.  8.  2.  3.  4.  3.  1.\n",
      "  9.  7.  5.  5.  0.  4.  3.  2.  5.  7.  3.  6.  5.  2.  8.  7.  2.  8.\n",
      "  2.  3.  9.  2.  3.  8.  8.  6.  8.  1.  4.  9.  7.  0.  1.  4.  3.  1.\n",
      "  3.  0.  8.  2.  1.  7.  9.  6.  2.  3.  3.  3.  7.  7.  9.  3.  2.  7.\n",
      "  0.  5.  4.  9.  2.  8.  1.  4.  4.  1.  6.  2.  7.  5.  8.  5.  4.  0.\n",
      "  0.  3.  4.  3.  7.  1.  3.  0.  9.  1.  7.  9.  2.  0.  9.  6.  4.  3.\n",
      "  7.  5.  9.  2.  3.  7.  3.  5.  2.  6.  8.  2.  0.  5.  5.  0.  6.  3.\n",
      "  4.  6.  9.  5.  1.  9.  8.  4.  0.  3.  7.  7.  1.  8.  1.  6.  9.  3.\n",
      "  1.  4.  8.  7.  4.  6.  7.  5.  5.  8.  1.  0.  7.  7.  0.  5.  7.  6.\n",
      "  6.  7.  0.  6.  5.  5.  3.  3.  9.  3.  7.  4.  7.  6.  1.  3.  5.  2.\n",
      "  1.  1.  8.  4.  1.  8.  7.  0.  3.  1.  0.  0.  6.  3.  7.  9.  2.  7.\n",
      "  7.  8.  5.  3.  2.  0.  8.  9.  2.  4.  4.  2.  3.  6.  5.  7.  5.  3.\n",
      "  1.  6.  0.  7.  5.  4.  4.  8.  0.  2.  4.  8.  8.  3.  2.  8.  1.  4.\n",
      "  2.  0.  3.  3.  5.  8.  7.  9.  7.  2.  8.  9.  1.  2.  4.  9.  1.  6.\n",
      "  5.  4.  3.  6.  6.  0.  8.  8.  6.  4.  4.  1.  7.  1.  8.  8.  6.  1.\n",
      "  6.  1.  0.  2.  1.  3.  4.  1.  0.  5.  9.  9.  2.  2.  4.  9.  8.  8.\n",
      "  6.  7.  0.  5.  5.  5.  5.  2.  7.  8.  0.  0.  6.  8.  1.  1.  2.  8.\n",
      "  0.  8.  2.  7.  7.  0.  7.  8.  0.  1.  0.  5.  5.  1.  4.  7.  5.  4.\n",
      "  9.  4.  4.  8.  2.  4.  8.  5.  6.  3.  4.  4.  8.  5.  3.  5.  1.  7.\n",
      "  0.  1.  5.  0.  9.  6.  4.  7.  4.  8.  3.  9.  5.  2.  5.  7.  4.  0.\n",
      "  5.  7.  3.  0.  6.  7.  7.  4.  5.  6.  5.  9.  5.  0.  2.  9.  5.  3.\n",
      "  3.  1.  1.  3.  3.  2.  9.  3.  3.  7.  1.  2.  6.  5.  5.  9.  5.  0.\n",
      "  9.  8.  0.  4.  4.  2.  5.  9.  3.  3.  1.  7.  8.  6.  8.  0.  0.  7.\n",
      "  7.  2.  5.  9.  0.  6.  3.  8.  6.  0.  3.  7.  9.  1.  9.  6.  9.  6.\n",
      "  1.  0.  1.  0.  9.  1.  5.  5.  2.  2.  5.  0.  8.  9.  2.  4.  3.  8.\n",
      "  8.  0.  0.  7.  3.  6.  7.  8.  7.  1.  5.  5.  6.  8.  7.  1.  3.  1.\n",
      "  9.  6.  9.  9.  9.  5.  1.  2.  4.  5.  8.  6.  4.  1.  7.  8.  6.  2.\n",
      "  3.  5.  9.  1.  0.  8.  4.  2.  9.  4.  7.  9.  3.  0.  8.  3.  7.  9.\n",
      "  6.  2.  4.  5.  5.  8.  4.  2.  0.  1.  3.  0.  3.  7.  0.  7.  7.  4.\n",
      "  8.  4.  5.  7.  8.  5.  9.  1.  3.  7.  2.  7.  7.  4.  6.  5.  4.  7.\n",
      "  7.  0.  9.  1.  0.  5.  2.  9.  7.  2.]\n",
      "FIT: dim(X)= [1000, 256]\n",
      "FIT: dim(y)= [1000, 1]\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "sample_code_submission/cifar10\n"
     ]
    }
   ],
   "source": [
    "print(M.is_trained)\n",
    "if not(M.is_trained):\n",
    "    X_train = D.data['X_train']\n",
    "    Y_train = D.data['Y_train']\n",
    "# Isabelle: do not convert\n",
    "   # Y_train = convert_label(Y_train)\n",
    "    M.fit(X_train, Y_train)   \n",
    "\n",
    "# print(len(y), y)\n",
    "Y_hat_train = M.predict(D.data['X_train']) # Optional, not really needed to test on taining examples\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])\n",
    "print(str(trained_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model (will be ready to reload next time around) and save the prediction results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_result(name_file, preds):\n",
    "    label_max = 9\n",
    "    f = open(name_file, 'w')\n",
    "    for pred in preds:\n",
    "        pred = int(pred)\n",
    "        tableau_pred = np.zeros((10, ))\n",
    "        for cpt, val in enumerate(tableau_pred):\n",
    "            f.write(str(val))\n",
    "            if cpt != label_max:\n",
    "                f.write(' ')\n",
    "            else:\n",
    "                f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('modele name : ', 'sample_code_submission/cifar10_model.pickle')\n",
      "sample_result_submission/cifar10_test.predict\r\n",
      "sample_result_submission/cifar10_test2.predict\r\n",
      "sample_result_submission/cifar10_train.predict\r\n",
      "sample_result_submission/cifar10_valid.predict\r\n",
      "sample_result_submission/cifar10_valid2.predict\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#save_result(result_name + '_valid2.predict', Y_hat_valid)\n",
    "#save_result(result_name + '_test2.predict', Y_hat_test)\n",
    "\n",
    "# PLEASE USE THE FUNCTION PROVIDED TO SAVE RESULTS WE WANT A UNIFORM FORMAT\n",
    "\n",
    "M.save(trained_model_name)                 \n",
    "result_name = 'sample_result_submission/' + dataname\n",
    "from data_io import write\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the results\n",
    "### Load the challenge metric\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. We use here the `mse_metric` metric (an example of organizer-supplied metric found in `my_metric.py`), which computes the mean-square-error. You may change that in the \"metric.txt\" file to e.g. use `bac_multiclass`, one of the AutoML challenge metrics found in `libscores.py`, which is 2*(balanced_accuracy)-1.\n",
    "<div style=\"background:#FFFFAA\"> \n",
    "I think `bac_multiclass` is the most appropriate metric for your challenge.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Using scoring metric:', 'bac_multiclass')\n"
     ]
    }
   ],
   "source": [
    "with open(score_dir + '/metric.txt', 'r') as f:\n",
    "    metric_name = f.readline().strip()\n",
    "import libscores, my_metric\n",
    "try:\n",
    "    scoring_function = getattr(libscores, metric_name)\n",
    "except:\n",
    "    scoring_function = getattr(my_metric, metric_name)\n",
    "print('Using scoring metric:', metric_name)\n",
    "??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training performance\n",
    "The participants normally posess target values (labels) only for training examples (except for the sample data). We compute with the `example` metric the training score, which should be zero for perfect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for the bac_multiclass metric = 0.8633\n",
      "Ideal score for the bac_multiclass metric = 1.0000\n"
     ]
    }
   ],
   "source": [
    "#name_label = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "#metrics = scoring_function(Y_train, Y_hat_train)\n",
    "#print(Y_train[0:10])\n",
    "#print(Y_hat_train[0:10])\n",
    "#ideal_metrics = scoring_function(Y_train, Y_train)\n",
    "#for cpt, m in enumerate(metrics):\n",
    "#    print('Training score for the class', name_label[cpt], 'metric = %5.4f' % m)\n",
    "#    print('Ideal score for the class ', name_label[cpt], 'metric = %5.4f' % ideal_metrics[0])\n",
    "\n",
    "#ISABELLE: I am not too sure what you did here\n",
    "print 'Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train)\n",
    "print 'Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful: some metrics use one-hot encoding for multi-class classification problems, but other use class numbers. So you need to convert the target values and predicted values if you want to use those. This is the case of `scikit-learn` metrics.\n",
    "<div style=\"background:#FFFFAA\"> If you want you can put confusion matrices in this section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert targets and predictions for vectors of class numbers:\n",
    "#from data_converter import convert_to_num\n",
    "#y_train = Y_train#convert_to_num(Y_train)\n",
    "#y_hat_train = Y_hat_train #convert_to_num(Y_hat_train)\n",
    "# Compute accuracy and confusion matrix:\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#print 'y_train     =' , y_train\n",
    "#print 'y_hat_train =' , y_hat_train\n",
    "#print('Training accuracy =', accuracy_score(y_train, y_hat_train))\n",
    "#print('Confusion matrix [known in lines, predicted in columns]=',confusion_matrix(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation performance\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development.\n",
    "<div style=\"background:#FFFFAA\"> \n",
    "I turned on verbose mode to show the conversion in model.py, you can turn it off later if you want.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to numeric vector\n",
      "[ 4.  0.  8.  4.  3.  7.  9.  7.  7.  9.  3.  3.  6.  9.  8.  1.  5.  9.\n",
      "  8.  5.  5.  6.  3.  3.  3.  0.  5.  1.  0.  6.  7.  3.  8.  0.  9.  0.\n",
      "  7.  0.  4.  8.  8.  0.  7.  5.  0.  3.  9.  0.  8.  6.  8.  7.  7.  6.\n",
      "  9.  4.  9.  1.  0.  8.  0.  6.  6.  7.  1.  6.  2.  8.  1.  1.  6.  0.\n",
      "  5.  4.  7.  8.  8.  1.  7.  4.  9.  6.  9.  8.  1.  2.  6.  1.  1.  8.\n",
      "  5.  3.  7.  4.  7.  1.  9.  2.  6.  9.  2.  4.  1.  0.  8.  2.  5.  2.\n",
      "  0.  0.  6.  6.  0.  8.  1.  4.  9.  2.  5.  8.  2.  2.  5.  8.  2.  5.\n",
      "  3.  4.  8.  2.  3.  4.  3.  1.  9.  7.  5.  5.  0.  4.  3.  2.  5.  7.\n",
      "  3.  6.  5.  2.  8.  7.  2.  8.  2.  3.  9.  2.  3.  8.  8.  6.  8.  1.\n",
      "  4.  9.  7.  0.  1.  4.  3.  1.  3.  0.  8.  2.  1.  7.  9.  6.  2.  3.\n",
      "  3.  3.  7.  7.  9.  3.  2.  7.  0.  5.  4.  9.  2.  8.  1.  4.  4.  1.\n",
      "  6.  2.  7.  5.  8.  5.  4.  0.  0.  3.  4.  3.  7.  1.  3.  0.  9.  1.\n",
      "  7.  9.  2.  0.  9.  6.  4.  3.  7.  5.  9.  2.  3.  7.  3.  5.  2.  6.\n",
      "  8.  2.  0.  5.  5.  0.  6.  3.  4.  6.  9.  5.  1.  9.  8.  4.  0.  3.\n",
      "  7.  7.  1.  8.  1.  6.  9.  3.  1.  4.  8.  7.  4.  6.  7.  5.  5.  8.\n",
      "  1.  0.  7.  7.  0.  5.  7.  6.  6.  7.  0.  6.  5.  5.  3.  3.  9.  3.\n",
      "  7.  4.  7.  6.  1.  3.  5.  2.  1.  1.  8.  4.  1.  8.  7.  0.  3.  1.\n",
      "  0.  0.  6.  3.  7.  9.  2.  7.  7.  8.  5.  3.  2.  0.  8.  9.  2.  4.\n",
      "  4.  2.  3.  6.  5.  7.  5.  3.  1.  6.  0.  7.  5.  4.  4.  8.  0.  2.\n",
      "  4.  8.  8.  3.  2.  8.  1.  4.  2.  0.  3.  3.  5.  8.  7.  9.  7.  2.\n",
      "  8.  9.  1.  2.  4.  9.  1.  6.  5.  4.  3.  6.  6.  0.  8.  8.  6.  4.\n",
      "  4.  1.  7.  1.  8.  8.  6.  1.  6.  1.  0.  2.  1.  3.  4.  1.  0.  5.\n",
      "  9.  9.  2.  2.  4.  9.  8.  8.  6.  7.  0.  5.  5.  5.  5.  2.  7.  8.\n",
      "  0.  0.  6.  8.  1.  1.  2.  8.  0.  8.  2.  7.  7.  0.  7.  8.  0.  1.\n",
      "  0.  5.  5.  1.  4.  7.  5.  4.  9.  4.  4.  8.  2.  4.  8.  5.  6.  3.\n",
      "  4.  4.  8.  5.  3.  5.  1.  7.  0.  1.  5.  0.  9.  6.  4.  7.  4.  8.\n",
      "  3.  9.  5.  2.  5.  7.  4.  0.  5.  7.  3.  0.  6.  7.  7.  4.  5.  6.\n",
      "  5.  9.  5.  0.  2.  9.  5.  3.  3.  1.  1.  3.  3.  2.  9.  3.  3.  7.\n",
      "  1.  2.  6.  5.  5.  9.  5.  0.  9.  8.  0.  4.  4.  2.  5.  9.  3.  3.\n",
      "  1.  7.  8.  6.  8.  0.  0.  7.  7.  2.  5.  9.  0.  6.  3.  8.  6.  0.\n",
      "  3.  7.  9.  1.  9.  6.  9.  6.  1.  0.  1.  0.  9.  1.  5.  5.  2.  2.\n",
      "  5.  0.  8.  9.  2.  4.  3.  8.  8.  0.  0.  7.  3.  6.  7.  8.  7.  1.\n",
      "  5.  5.  6.  8.  7.  1.  3.  1.  9.  6.  9.  9.  9.  5.  1.  2.  4.  5.\n",
      "  8.  6.  4.  1.  7.  8.  6.  2.  3.  5.  9.  1.  0.  8.  4.  2.  9.  4.\n",
      "  7.  9.  3.  0.  8.  3.  7.  9.  6.  2.  4.  5.  5.  8.  4.  2.  0.  1.\n",
      "  3.  0.  3.  7.  0.  7.  7.  4.  8.  4.  5.  7.  8.  5.  9.  1.  3.  7.\n",
      "  2.  7.  7.  4.  6.  5.  4.  7.  7.  0.  9.  1.  0.  5.  2.  9.  7.  2.]\n",
      "FIT: dim(X)= [666, 256]\n",
      "FIT: dim(y)= [666, 1]\n",
      "PREDICT: dim(X)= [334, 256]\n",
      "PREDICT: dim(y)= [334, 1]\n",
      "('Fold', 1, 'example metric = ', 0.84916944280689588)\n",
      "Converting to numeric vector\n",
      "[ 6.  1.  6.  6.  8.  8.  3.  4.  6.  0.  6.  9.  0.  3.  6.  6.  5.  4.\n",
      "  8.  3.  2.  6.  4.  0.  3.  1.  4.  0.  6.  6.  2.  7.  6.  3.  9.  0.\n",
      "  4.  5.  7.  1.  6.  7.  9.  1.  2.  7.  7.  8.  0.  3.  7.  4.  7.  3.\n",
      "  1.  4.  0.  4.  6.  6.  1.  4.  9.  2.  6.  4.  4.  5.  0.  4.  6.  0.\n",
      "  8.  3.  4.  8.  8.  1.  3.  9.  5.  7.  1.  9.  4.  7.  9.  1.  4.  9.\n",
      "  7.  5.  2.  7.  3.  4.  8.  8.  2.  2.  1.  5.  9.  2.  7.  8.  8.  6.\n",
      "  8.  8.  2.  8.  1.  3.  8.  8.  5.  4.  7.  1.  6.  6.  3.  1.  6.  1.\n",
      "  6.  7.  0.  4.  6.  9.  5.  8.  8.  7.  1.  9.  0.  3.  3.  7.  6.  9.\n",
      "  0.  0.  4.  7.  1.  4.  3.  4.  3.  9.  8.  6.  7.  0.  8.  3.  9.  1.\n",
      "  0.  8.  0.  9.  8.  4.  0.  2.  1.  4.  2.  7.  1.  7.  0.  5.  2.  9.\n",
      "  7.  9.  8.  6.  4.  4.  1.  1.  6.  7.  8.  8.  6.  4.  5.  6.  3.  9.\n",
      "  4.  6.  2.  5.  3.  6.  7.  7.  3.  9.  1.  3.  4.  1.  8.  3.  3.  5.\n",
      "  6.  4.  0.  9.  6.  7.  3.  6.  5.  0.  6.  2.  0.  5.  4.  9.  3.  1.\n",
      "  4.  6.  0.  6.  7.  0.  7.  2.  6.  9.  1.  6.  5.  4.  5.  4.  7.  7.\n",
      "  6.  8.  1.  4.  5.  9.  7.  8.  8.  7.  1.  4.  6.  4.  6.  2.  2.  5.\n",
      "  0.  3.  8.  9.  4.  1.  1.  2.  4.  1.  9.  6.  3.  3.  6.  9.  5.  7.\n",
      "  3.  6.  9.  4.  2.  4.  0.  0.  0.  8.  7.  9.  5.  1.  8.  6.  7.  0.\n",
      "  1.  7.  7.  8.  6.  2.  7.  4.  8.  8.  9.  8.  9.  8.  2.  9.  8.  9.\n",
      "  1.  3.  5.  7.  4.  0.  1.  4.  1.  9.  6.  0.  7.  5.  4.  4.  8.  0.\n",
      "  2.  4.  8.  8.  3.  2.  8.  1.  4.  2.  0.  3.  3.  5.  8.  7.  9.  7.\n",
      "  2.  8.  9.  1.  2.  4.  9.  1.  6.  5.  4.  3.  6.  6.  0.  8.  8.  6.\n",
      "  4.  4.  1.  7.  1.  8.  8.  6.  1.  6.  1.  0.  2.  1.  3.  4.  1.  0.\n",
      "  5.  9.  9.  2.  2.  4.  9.  8.  8.  6.  7.  0.  5.  5.  5.  5.  2.  7.\n",
      "  8.  0.  0.  6.  8.  1.  1.  2.  8.  0.  8.  2.  7.  7.  0.  7.  8.  0.\n",
      "  1.  0.  5.  5.  1.  4.  7.  5.  4.  9.  4.  4.  8.  2.  4.  8.  5.  6.\n",
      "  3.  4.  4.  8.  5.  3.  5.  1.  7.  0.  1.  5.  0.  9.  6.  4.  7.  4.\n",
      "  8.  3.  9.  5.  2.  5.  7.  4.  0.  5.  7.  3.  0.  6.  7.  7.  4.  5.\n",
      "  6.  5.  9.  5.  0.  2.  9.  5.  3.  3.  1.  1.  3.  3.  2.  9.  3.  3.\n",
      "  7.  1.  2.  6.  5.  5.  9.  5.  0.  9.  8.  0.  4.  4.  2.  5.  9.  3.\n",
      "  3.  1.  7.  8.  6.  8.  0.  0.  7.  7.  2.  5.  9.  0.  6.  3.  8.  6.\n",
      "  0.  3.  7.  9.  1.  9.  6.  9.  6.  1.  0.  1.  0.  9.  1.  5.  5.  2.\n",
      "  2.  5.  0.  8.  9.  2.  4.  3.  8.  8.  0.  0.  7.  3.  6.  7.  8.  7.\n",
      "  1.  5.  5.  6.  8.  7.  1.  3.  1.  9.  6.  9.  9.  9.  5.  1.  2.  4.\n",
      "  5.  8.  6.  4.  1.  7.  8.  6.  2.  3.  5.  9.  1.  0.  8.  4.  2.  9.\n",
      "  4.  7.  9.  3.  0.  8.  3.  7.  9.  6.  2.  4.  5.  5.  8.  4.  2.  0.\n",
      "  1.  3.  0.  3.  7.  0.  7.  7.  4.  8.  4.  5.  7.  8.  5.  9.  1.  3.\n",
      "  7.  2.  7.  7.  4.  6.  5.  4.  7.  7.  0.  9.  1.  0.  5.  2.  9.  7.\n",
      "  2.]\n",
      "FIT: dim(X)= [667, 256]\n",
      "FIT: dim(y)= [667, 1]\n",
      "PREDICT: dim(X)= [333, 256]\n",
      "PREDICT: dim(y)= [333, 1]\n",
      "('Fold', 2, 'example metric = ', 0.84920507043707449)\n",
      "Converting to numeric vector\n",
      "[ 6.  1.  6.  6.  8.  8.  3.  4.  6.  0.  6.  9.  0.  3.  6.  6.  5.  4.\n",
      "  8.  3.  2.  6.  4.  0.  3.  1.  4.  0.  6.  6.  2.  7.  6.  3.  9.  0.\n",
      "  4.  5.  7.  1.  6.  7.  9.  1.  2.  7.  7.  8.  0.  3.  7.  4.  7.  3.\n",
      "  1.  4.  0.  4.  6.  6.  1.  4.  9.  2.  6.  4.  4.  5.  0.  4.  6.  0.\n",
      "  8.  3.  4.  8.  8.  1.  3.  9.  5.  7.  1.  9.  4.  7.  9.  1.  4.  9.\n",
      "  7.  5.  2.  7.  3.  4.  8.  8.  2.  2.  1.  5.  9.  2.  7.  8.  8.  6.\n",
      "  8.  8.  2.  8.  1.  3.  8.  8.  5.  4.  7.  1.  6.  6.  3.  1.  6.  1.\n",
      "  6.  7.  0.  4.  6.  9.  5.  8.  8.  7.  1.  9.  0.  3.  3.  7.  6.  9.\n",
      "  0.  0.  4.  7.  1.  4.  3.  4.  3.  9.  8.  6.  7.  0.  8.  3.  9.  1.\n",
      "  0.  8.  0.  9.  8.  4.  0.  2.  1.  4.  2.  7.  1.  7.  0.  5.  2.  9.\n",
      "  7.  9.  8.  6.  4.  4.  1.  1.  6.  7.  8.  8.  6.  4.  5.  6.  3.  9.\n",
      "  4.  6.  2.  5.  3.  6.  7.  7.  3.  9.  1.  3.  4.  1.  8.  3.  3.  5.\n",
      "  6.  4.  0.  9.  6.  7.  3.  6.  5.  0.  6.  2.  0.  5.  4.  9.  3.  1.\n",
      "  4.  6.  0.  6.  7.  0.  7.  2.  6.  9.  1.  6.  5.  4.  5.  4.  7.  7.\n",
      "  6.  8.  1.  4.  5.  9.  7.  8.  8.  7.  1.  4.  6.  4.  6.  2.  2.  5.\n",
      "  0.  3.  8.  9.  4.  1.  1.  2.  4.  1.  9.  6.  3.  3.  6.  9.  5.  7.\n",
      "  3.  6.  9.  4.  2.  4.  0.  0.  0.  8.  7.  9.  5.  1.  8.  6.  7.  0.\n",
      "  1.  7.  7.  8.  6.  2.  7.  4.  8.  8.  9.  8.  9.  8.  2.  9.  8.  9.\n",
      "  1.  3.  5.  7.  4.  0.  1.  4.  1.  9.  4.  0.  8.  4.  3.  7.  9.  7.\n",
      "  7.  9.  3.  3.  6.  9.  8.  1.  5.  9.  8.  5.  5.  6.  3.  3.  3.  0.\n",
      "  5.  1.  0.  6.  7.  3.  8.  0.  9.  0.  7.  0.  4.  8.  8.  0.  7.  5.\n",
      "  0.  3.  9.  0.  8.  6.  8.  7.  7.  6.  9.  4.  9.  1.  0.  8.  0.  6.\n",
      "  6.  7.  1.  6.  2.  8.  1.  1.  6.  0.  5.  4.  7.  8.  8.  1.  7.  4.\n",
      "  9.  6.  9.  8.  1.  2.  6.  1.  1.  8.  5.  3.  7.  4.  7.  1.  9.  2.\n",
      "  6.  9.  2.  4.  1.  0.  8.  2.  5.  2.  0.  0.  6.  6.  0.  8.  1.  4.\n",
      "  9.  2.  5.  8.  2.  2.  5.  8.  2.  5.  3.  4.  8.  2.  3.  4.  3.  1.\n",
      "  9.  7.  5.  5.  0.  4.  3.  2.  5.  7.  3.  6.  5.  2.  8.  7.  2.  8.\n",
      "  2.  3.  9.  2.  3.  8.  8.  6.  8.  1.  4.  9.  7.  0.  1.  4.  3.  1.\n",
      "  3.  0.  8.  2.  1.  7.  9.  6.  2.  3.  3.  3.  7.  7.  9.  3.  2.  7.\n",
      "  0.  5.  4.  9.  2.  8.  1.  4.  4.  1.  6.  2.  7.  5.  8.  5.  4.  0.\n",
      "  0.  3.  4.  3.  7.  1.  3.  0.  9.  1.  7.  9.  2.  0.  9.  6.  4.  3.\n",
      "  7.  5.  9.  2.  3.  7.  3.  5.  2.  6.  8.  2.  0.  5.  5.  0.  6.  3.\n",
      "  4.  6.  9.  5.  1.  9.  8.  4.  0.  3.  7.  7.  1.  8.  1.  6.  9.  3.\n",
      "  1.  4.  8.  7.  4.  6.  7.  5.  5.  8.  1.  0.  7.  7.  0.  5.  7.  6.\n",
      "  6.  7.  0.  6.  5.  5.  3.  3.  9.  3.  7.  4.  7.  6.  1.  3.  5.  2.\n",
      "  1.  1.  8.  4.  1.  8.  7.  0.  3.  1.  0.  0.  6.  3.  7.  9.  2.  7.\n",
      "  7.  8.  5.  3.  2.  0.  8.  9.  2.  4.  4.  2.  3.  6.  5.  7.  5.  3.\n",
      "  1.]\n",
      "FIT: dim(X)= [667, 256]\n",
      "FIT: dim(y)= [667, 1]\n",
      "PREDICT: dim(X)= [333, 256]\n",
      "PREDICT: dim(y)= [333, 1]\n",
      "('Fold', 3, 'example metric = ', 0.84608557523293015)\n",
      "('Average score = ', 0.84815336282563347)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from numpy import zeros, mean\n",
    "# 3-fold cross-validation\n",
    "n = 3\n",
    "kf = KFold(n_splits=n)\n",
    "kf.get_n_splits(X_train)\n",
    "i=0\n",
    "scores = zeros(n)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    Xtr, Xva = X_train[train_index], X_train[test_index]\n",
    "    Ytr, Yva = Y_train[train_index], Y_train[test_index]\n",
    "    M = model()\n",
    "    M.fit(Xtr, Ytr)\n",
    "    Yhat = M.predict(Xva)\n",
    "    scores[i] = scoring_function(Yva, Yhat)\n",
    "    print ('Fold', i+1, 'example metric = ', scores[i])\n",
    "    i=i+1\n",
    "print ('Average score = ', mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Making a submission\n",
    "\n",
    "## Unit testing\n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdir = 'sample_result_submission'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input_dir: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data\n",
      "Using output_dir: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_result_submission\n",
      "Using program_dir: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/ingestion_program\n",
      "Using submission_dir: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_code_submission\n",
      "\n",
      "========== Ingestion program version 6 ==========\n",
      "\n",
      "************************************************\n",
      "******** Processing dataset Cifar10 ********\n",
      "************************************************\n",
      "========= Reading and converting data ==========\n",
      "Info file found : /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_public.info\n",
      "========= Reading /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_train.data\n",
      "[+] Success in  0.05 sec\n",
      "========= Reading /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_train.solution\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_valid.data\n",
      "[+] Success in  0.05 sec\n",
      "========= Reading /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_data/cifar10_test.data\n",
      "[+] Success in  0.04 sec\n",
      "DataManager : cifar10\n",
      "info:\n",
      "\ttask = multiclass.classification\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tname = cifar10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tfeat_type = Numerical\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tis_sparse = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tmetric = accuracy_metric\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\ttarget_type = Numerical\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\ttest_num = 10000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tlabel_num = 10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\ttarget_num = 1\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tvalid_num = 10000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\thas_categorical = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tusage = dataset cifar10\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\tfeat_num = 256\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\ttime_budget = 1200\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\ttrain_num = 40000\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\thas_missing = 0\n",
      "data:\n",
      "\tX_train = array(1000, 256)\n",
      "\tY_train = array(1000, 10)\n",
      "\tX_valid = array(1000, 256)\n",
      "\tX_test = array(1000, 256)\n",
      "feat_type:\tarray(256,)\n",
      "feat_idx:\tarray(256,)\n",
      "\n",
      "[+] Size of uploaded data  72.00 bytes\n",
      "[+] Cumulated time budget (all tasks so far)  1200.00 sec\n",
      "[+] Time budget for this task 1200.00 sec\n",
      "[+] Remaining time after reading data 1199.86 sec\n",
      "======== Creating model ==========\n",
      "**********************************************************\n",
      "****** Attempting to reload model to avoid training ******\n",
      "**********************************************************\n",
      "Model reloaded from: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_code_submission/cifar10_model.pickle\n",
      "[+] Model reloaded, no need to train!\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "PREDICT: dim(X)= [1000, 256]\n",
      "PREDICT: dim(y)= [1000, 1]\n",
      "[+] Prediction success, time spent so far  0.18 sec\n",
      "======== Saving results to: /Users/isabelleguyon/Documents/Projects/ParisSaclay/Enseignement/Winter2018/M2_AIC/2.starting_kit/vision_multiclass/Starting_kit/sample_result_submission\n",
      "[+] Results saved, time spent so far  0.24 sec\n",
      "[+] End cycle, time left 1199.76 sec\n",
      "[+] Done\n",
      "[+] Overall time spent  1.33 sec ::  Overall time budget 1200.00 sec\n"
     ]
    }
   ],
   "source": [
    "!python $problem_dir/ingestion.py $datadir $outdir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing the submission\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
